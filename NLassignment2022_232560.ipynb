{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2S8I2ny-ovS"
      },
      "source": [
        "# NLE Assignment: Sentiment Classification\n",
        "\n",
        "In this assignment, you will be investigating NLP methods for distinguishing positive and negative reviews written about movies.\n",
        "\n",
        "For assessment, you are expected to complete and submit this notebook file.  When answers require code, you may import and use library functions (unless explicitly told otherwise).  All of your own code should be included in the notebook rather than imported from elsewhere.  Written answers should also be included in the notebook.  You should insert as many extra cells as you want and change the type between code and markdown as appropriate.\n",
        "\n",
        "In order to avoid misconduct, you should not talk about the assignment questions with your peers.  If you are not sure what a question is asking you to do or have any other questions, please ask me or one of the Teaching Assistants.\n",
        "\n",
        "Marking guidelines are provided as a separate document.\n",
        "\n",
        "The first few cells contain code to set-up the assignment and bring in some data.   In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell.  Otherwise do not change the code in these cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1gXQAZas-l9c"
      },
      "outputs": [],
      "source": [
        "candidateno=232560 #this MUST be updated to your candidate number so that you get a unique data sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nk8JTP88A8vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ea254d-0b91-4e3b-e470-a03bca54b189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#do not change the code in this cell\n",
        "#preliminary imports\n",
        "\n",
        "#set up nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "#for setting up training and testing data\n",
        "import random\n",
        "\n",
        "#useful other tools\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from itertools import zip_longest\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.classify.api import ClassifierI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "BHBkzAccCVaZ"
      },
      "outputs": [],
      "source": [
        "#do not change the code in this cell\n",
        "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
        "    \"\"\"\n",
        "    Given corpus generator and ratio:\n",
        "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
        "\n",
        "    :param data: A corpus generator.\n",
        "    :param ratio: The proportion of training documents (default 0.7)\n",
        "    :return: a pair (tuple) of lists where the first element of the \n",
        "            pair is a list of the training data and the second is a list of the test data.\n",
        "    \"\"\"\n",
        "    \n",
        "    data = list(data)  \n",
        "    n = len(data)  \n",
        "    train_indices = random.sample(range(n), int(n * ratio))          \n",
        "    test_indices = list(set(range(n)) - set(train_indices))    \n",
        "    train = [data[i] for i in train_indices]           \n",
        "    test = [data[i] for i in test_indices]             \n",
        "    return (train, test)                       \n",
        " \n",
        "\n",
        "def get_train_test_data():\n",
        "    \n",
        "    #get ids of positive and negative movie reviews\n",
        "    pos_review_ids=movie_reviews.fileids('pos')\n",
        "    neg_review_ids=movie_reviews.fileids('neg')\n",
        "   \n",
        "    #split positive and negative data into training and testing sets\n",
        "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
        "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
        "    #add labels to the data and concatenate\n",
        "    training = [(movie_reviews.words(f),'pos') for f in pos_train_ids]+[(movie_reviews.words(f),'neg') for f in neg_train_ids]\n",
        "    testing = [(movie_reviews.words(f),'pos') for f in pos_test_ids]+[(movie_reviews.words(f),'neg') for f in neg_test_ids]\n",
        "   \n",
        "    return training, testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N3LWwBYICPP"
      },
      "source": [
        "When you have run the cell below, your unique training and testing samples will be stored in `training_data` and `testing_data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "HJLegkdPFUJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f1908a-0df3-45b0-c6d4-a0389dcce2b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The amount of training data is 1400\n",
            "The amount of testing data is 600\n",
            "The representation of a single data item is below\n",
            "(['an', 'unhappy', 'italian', 'housewife', ',', 'a', ...], 'pos')\n"
          ]
        }
      ],
      "source": [
        "#do not change the code in this cell\n",
        "random.seed(candidateno)\n",
        "training_data,testing_data=get_train_test_data()\n",
        "print(\"The amount of training data is {}\".format(len(training_data)))\n",
        "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
        "print(\"The representation of a single data item is below\")\n",
        "print(training_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE3bKQbB50Rq"
      },
      "source": [
        "1)  \n",
        "a) **Generate** a list of 10 content words which are representative of the positive reviews in your training data.\n",
        "\n",
        "b) **Generate** a list of 10 content words which are representative of the negative reviews in your training data.\n",
        "\n",
        "c) **Explain** what you have done and why\n",
        "\n",
        "[20\\%]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pos_Normal_list = []\n",
        "Neg_Normal_list = []\n",
        "\n",
        "stop_words = set(stopwords.words('english')) #Takes the set of stop words from nltk in order to filter more important words into the list.\n",
        "for i, Type in training_data: #first iteration, goes over each item in the training data and seperates the tuples into their respective tags and contents.\n",
        "  if Type == 'pos': #The first filter, this checks the tag of the tuple to see if its a positive or negative review, if its positive it goes through.\n",
        "    for j in i: #iteration over the i, the i in this case being the other half of the tuple which is the review itself.\n",
        "      if j.isalpha() and j not in stop_words and len(j) > 1: #The removal of unnecessary and undesirable contents by filtering, this first removes any punctuation, followed by any stop words and any unwanted fat like the word 'the', and finally it checks the length, and removes anything of length less than 1 which could be anything else like the cut offs of punctuation.\n",
        "        Pos_Normal_list.append(j) #The wanted words, are then appended to a list which is just the desirable words\n",
        "\n",
        "  elif Type == 'neg': #the same as the positive is done here, to the negative reviews in the corpus.\n",
        "    for m in i: #This iterates once again over all the words inside the review itself\n",
        "      if m.isalpha() and m not in stop_words and len(m) > 1: #A filter to remove the fat of the reviews and gets the most key words\n",
        "        Neg_Normal_list.append(m) #and finally this is once again appended to the negative version of the list\n",
        "\n",
        "counted_Pos = FreqDist(Pos_Normal_list) #The freqeuncy distribution of the reviews are calculated. This meaning for every time a word is counted, it is marked in a new tuple of the word itself and then the count. This can then be looked through the get the most common words.\n",
        "print(counted_Pos) #A printed version of the words, with the outcomes being the number of words in the whole review, only positive for this set, and the samples being the numer of variations of the words inside the positive reviews\n",
        "\n",
        "\n",
        "      \n",
        "counted_Neg = FreqDist(Neg_Normal_list)#another frequency distribution of the reviews, this being only the negative version of all the words that appear inside the review\n",
        "print(counted_Neg)#The finale piece, which is the amount of words totally caluclated in the negative reviews and the variations of those words.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx_ieC37gE0h",
        "outputId": "c1d206ef-f2f5-490a-c027-0c12cb165637"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FreqDist with 25580 samples and 263178 outcomes>\n",
            "<FreqDist with 24003 samples and 229957 outcomes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_Diff = counted_Neg - counted_Pos #This gives the best negative words, by taking all the negative words and removing versions of them that appear in the positive version, this makes a better list of words as similar words that may be very common in both, for example the stop words we have already removed, are reduced in the number of times they show up\n",
        "pos_Diff = counted_Pos - counted_Neg #This is good because it means common words that aren't stop words but that are still common in the language, are reduced giving a more accurate representation of the positive words specifically.\n",
        "\n",
        "Top10_pos_Diff = pos_Diff.most_common(10)#skims off the top 10 words of the list and creates a specifically dedicated list of them, just incase we want to do more with the rest of the words later\n",
        "Top10_neg_Diff = neg_Diff.most_common(10)#the same as above, however on the negative words\n",
        "\n",
        "print(Top10_pos_Diff) #printed versions of the top 10 positive and\n",
        "print(Top10_neg_Diff) #negative words"
      ],
      "metadata": {
        "id": "ll7BM3PEhtEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ab4b01-5d66-4422-e3cb-8f623cb542b0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('film', 764), ('life', 383), ('also', 320), ('great', 252), ('well', 247), ('films', 241), ('story', 239), ('one', 225), ('many', 219), ('best', 217)]\n",
            "[('movie', 581), ('bad', 475), ('plot', 270), ('even', 147), ('worst', 146), ('nothing', 135), ('script', 120), ('boring', 120), ('could', 114), ('least', 113)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This generates a set of words from the corpus of reviews given. Firstly, because each of the reviews already have a tag of positive or negative as training data, they can be filtered out to either be positive or negative and then that information can be worked on more efficiently. Each review is then passed through a filter, in order to remove any unwanted words. These are either stop words, common words that are of no weight, words that are not alphabetical in nature, IE punctuation, and finally just to make sure anything of length 1. The removal of anything of length 1 is because this double checks no punctuation gets through, as well as skimming off any cut off letters like the t in wasn't or just the letter I when talking in first person. \n",
        " \n",
        "From there, I append the new filtered word to a list, not worrying about repeated words or position in the list. A frequency distribution analysis is done on the two separated lists, creating a dictionary of each word that appears, and the number of times that it shows up. This frequency of words is important as it provides valuable information on what kind of words are used in positive and negative reviews of a piece. It is now possible to essentially do maths on these two lists, as they comprise a tuple of their tag, word, and their value, the count. If we were to subtract the two lists from one another, then we can remove the information that is present in both sets. The information removed is essentially more stop words, or words that are used commonly in the English language. \n",
        " \n",
        "Finally, this leaves two dictionaries of the most common words in both review types, being the most essential and common words used to convey information. The top 10 of these dictionaries can then be taken, these being the most common top 10, and put into a dedicated list that can be used.\n",
        "\n"
      ],
      "metadata": {
        "id": "sJenKnz3PyP9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TApOQE6vND20"
      },
      "source": [
        "2) \n",
        "a) **Use** the lists generated in Q1 to build a **word list classifier** which will classify reviews as being positive or negative.\n",
        "\n",
        "b) **Explain** what you have done.\n",
        "\n",
        "[12.5\\%]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "BThDMrcmODJy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1b1cda3e-378b-44c7-fcd9-154fd24cb6e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['as', 'a', 'devout', 'atheist', 'and', 'an', 'avowed', ...], 'pos')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "def classify(Review,Size): #new function, that takes a review of either a string (see below) or a tuple. This tuple is comprised of a normalised list of lower case words and punctuation and a tag.\n",
        "  #Review = Review.split() #This can be uncommented to take string inputs and classify them however i have commented it to use the more informative testing data in order to show that it is working.\n",
        "  score = 0 #A new score value\n",
        "  TopSize_pos_Diff = pos_Diff.most_common(Size) \n",
        "  TopSize_neg_Diff = neg_Diff.most_common(Size)\n",
        "  \n",
        "  for j in Review: #This iterates over the words in the review passed in, and then checks if they are in the positive or negative lists\n",
        "    for i,value in TopSize_pos_Diff: #This takes the first word in the top 10 list, and iterates over all the words in the top 10 list. This is not very efficient\n",
        "      if i == j: #Checks if the word in the review, is the word in the top 10 list. if it is then a point is added to the score making it more positive\n",
        "        score = score + 1 #The addition of a point to score, with each word in the top 10 being valued at a weight of 1\n",
        "    for i,value in TopSize_neg_Diff: #Same as the version above, but for negatives.\n",
        "      if i == j: #**\n",
        "        score = score - 1 #**\n",
        "      \n",
        "  if score > 0: #The identifier for whether a review is positive or negative, dependant on the total weight of the score\n",
        "    return(\"pos\")\n",
        "  else:\n",
        "    return(\"neg\")\n",
        "\n",
        "#classify(\"film life film also great also well even worst nothing script plot\") #For the version where strings want to be accepted\n",
        "\n",
        "random_num = random.randint(0, len(testing_data)) #This generates a random number, which is used to take a random review from the testing data. This is put through the classifier to demonstrate what it is doing.\n",
        "random_tuple = testing_data[random_num]\n",
        "random_list = random_tuple[0]\n",
        "\n",
        "print(random_tuple)\n",
        "classify(random_list,10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classification process takes a review as an input, this appears as a tuple with a list alongside a tag. This tag is either positive or negative for training purposes, and the list is just words that are part of a review. This is gone through, one word at a time, and compared to the top 10 list I created in the previous question. If the word inside the review currently being checked is the same as the word from the list of positive reviews, a point is added. The weight of each word in the review is the same, with each occurance being 1. Once this is complete, the same thing will happen in the negative list, however each word from this list has a negative weight of -1, taking points from the score. Totally, this will weigh up to be a positive or negative review and this information will be returned.\n",
        " \n",
        "In a proper classifier, it would be smarter to use the entire set of the dictionary created with each word carrying a proper value. This would consist of maybe the top 10 words having a value of 3, the top 100 being a value of two and everything else having a value of 1. This would give a more accurate representation of the data.\n",
        " \n",
        "Finally, for demonstration purposes, a random piece of testing data is chosen and it is used to show the actual marking already applied to it, as well as the predicted review type as it goes through the classifier.\n",
        "\n",
        "For the questions below, i have also implemented now a Size parameter. This means i can manipulate and change the sample size IE the length of the word list repeatedly with only one small change to the call of this function. This means for the experiment below is a simpler and easier process\n"
      ],
      "metadata": {
        "id": "mfApq0vYQ486"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL1iL9jg50Rv"
      },
      "source": [
        "3)\n",
        "a) **Calculate** the accuracy, precision, recall and F1 score of your classifier.\n",
        "\n",
        "b) Is it reasonable to evaluate the classifier in terms of its accuracy?  **Explain** your answer and give a counter-example (a scenario where it would / would not be reasonable to evaluate the classifier in terms of its accuracy).\n",
        "\n",
        "[20\\%]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "r1PrZnTe50Rw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a86956-85d0-465a-dc0a-555547f7b9db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(260, 107, 193, 40, 0.6116666666666667)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def accuracy_class_testing(classifier,Size): #Function creation, this will take a classifier IE the one i made above or the naive bayes one used later, and put it through its paces with the testing data\n",
        "  accuracy = 0 #Variable declaration\n",
        "  True_Pos = 0\n",
        "  True_Neg = 0\n",
        "  False_Pos = 0\n",
        "  False_Neg = 0\n",
        "\n",
        "  for i in range (0,len(testing_data)): #For loop, this iterates the same number of times as the length of the testing data. This is 600 for my purposes but if the testing data was changed this could change with it\n",
        "    testing = testing_data[i] #The variable testing takes the value at position i of each iteration for testing upon it\n",
        "    classified = classifier(testing[0],Size) #classification of the data, this puts the review at the iterative into the classifier and assigns it to the variable classified to be checked again later\n",
        "    if classified == testing[1]: #filtering, if the statement is true IE did the classifier get the result correct it passes, else it doesnt\n",
        "      if classified == 'neg': #true negatives get a mark for the testing later\n",
        "        True_Neg += 1\n",
        "      elif classified == 'pos': #all true positives get a mark\n",
        "        True_Pos += 1\n",
        "      accuracy += 1 #if either of these are the case, IE the classifier gets it correct, then a point is added to the accuracy. The closer this is to the value of len(testing_data) the more accurate the result\n",
        "    elif classified == 'neg':#if the first set of filtering fails it comes here, where it checks if it negative and fail meaning a false negative\n",
        "      False_Neg += 1\n",
        "    elif classified == 'pos':#the same as the negative above, however marks down a false positive\n",
        "      False_Pos += 1\n",
        "  accuracy = accuracy/len(testing_data) #finale creation of accuracy, this divides the value of accuracy counted above by the length of the testing data giving a percentage of how much was correct\n",
        "  return(True_Pos, True_Neg, False_Pos, False_Neg, accuracy) #the return statement, this gives the values of all the TP,TN,FP,FN and accuracy to be used in other functions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(accuracy_class_testing(classify,10))#a demonstration, to get the accuracy of the classifier i made using a word list length of 10, if this is changed the accuracy increases, to a point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Uq4Fmr8S50Rx"
      },
      "outputs": [],
      "source": [
        "\n",
        "def precision_testing(True_Pos,True_Neg,False_Pos,False_Neg): #new function of precision, this takes all the inputs however only two are needed\n",
        "  if True_Pos and False_Pos != 0: #filters out the unlikely possability that no 0 values are given for true or false positives, this would cause a divide by 0 exception to be thrown if it got through\n",
        "    precise = True_Pos / (True_Pos + False_Pos) #An actual calculation of the precision of the data is made\n",
        "  else: #when 0 values are found it goes to the else, which just puts the precision as 0. This portion in all of these functions causes problems on small data samples\n",
        "    precise = 0\n",
        "  return(precise) #returns the values of precision to be used in the F1 score later\n",
        "\n",
        "def recall_testing(True_Pos,True_Neg,False_Pos,False_Neg):#new function of recall, takes all inputs again but only needs two\n",
        "  if True_Pos and False_Neg != 0:#Filter of 0 results on small data sets\n",
        "    recalled = True_Pos / (True_Pos + False_Neg)#Math is done on the values to get the recall value,\n",
        "  else:\n",
        "    recalled = 0\n",
        "  return(recalled)#the return of the recall value for use in F1\n",
        "\n",
        "def F1_Score_testing(prec,rec):#New funciton, this takes only the precision and the recall as calculated above\n",
        "  if prec and rec != 0: #filters out the possibility that prec or rec are 0 and gives a representative value\n",
        "    F1_able = (2 * prec * rec) / (prec + rec) #the calculation is done to get the f1 score as given by the recall and precision values\n",
        "  else:\n",
        "    F1_able = 0 \n",
        "  return(F1_able) #The return of the F1 value for use in analytics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NJhRGovu50Ry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22907035-0169-451e-c2f8-2383d298247c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6116666666666667, 0.5739514348785872, 0.8666666666666667, 0.6905710491367862]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def AC_PR_RE_F1_testing(Accuracy_Of_Classifier): #This is a function that creates a list of the data, this is important as assembles all the data into a simple 4 piece list that can be used for anaylsis.\n",
        "  Temp_position = Accuracy_Of_Classifier #A temporary place holder for True and false positives and negatives\n",
        "  num_list = [] #A new list that holds the positions so they can be put into their correct identifiers.\n",
        "  for i in Temp_position: #For each item in this list, the value is then put into another list to ensure continuity between the values of a function and their needs. This isnt necessary however is simpler to lay out for many classifier types\n",
        "    num_list.append(i) #The actual items being added\n",
        "  True_Pos = num_list[0] #A value of the item is given its correct identifier to pass into the other functions\n",
        "  True_Neg = num_list[1] #**\n",
        "  False_Pos = num_list[2] #**\n",
        "  False_Neg = num_list[3] #**\n",
        "  accu = num_list[4] #This is slightly different, as the accuracy is calulated alongside the true/false negatives/positives. This is the first piece of the output list\n",
        "\n",
        "  prec = precision_testing(True_Pos,True_Neg,False_Pos,False_Neg) #Calls the function of precision, using the values passed from the accuracy calculator and saves this new value to a independent variable\n",
        "  rec = recall_testing(True_Pos,True_Neg,False_Pos,False_Neg) #Calls the funciton of Recall, once again passing the tures and falses and saves this new value to a independent variable\n",
        "  F1 = F1_Score_testing(prec,rec) #And finally, as the recall and precision are calculated, their values are passed into the F1 score to get a value as well\n",
        "  \n",
        "  \n",
        "  return([accu,prec,rec,F1]) #All variables are assembled into a simple list to be accessed on call as they are needed on a return.\n",
        "\n",
        "print(AC_PR_RE_F1_testing(accuracy_class_testing(classify,10)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gHYwj0i50Ry"
      },
      "source": [
        "It is not reasonable to evaluate the classifier on its accuracy alone. In the case given to use, we have a binary classification of either positive or negative. If we were given some testing data that was perfectly balanced and then had a classifier that only chose positive, the result would be an accuracy of 50%. This is just guessing alone and is not valuable information. \n",
        " \n",
        "If you were to evaluate a classifier by accuracy, you could ask it to pick one or the other every time giving it the 50/50 chance on balanced data. However, if you were to get a set of data that was highly imbalanced, say 95/5 positive to negative, you would get an accuracy of either 95% or only 5%. From there you could assume you have either a very good classifier or an abysmal one that is so much worse than even randomly guessing on balanced data. In a real world situation, you don't know the balance of the data being given to the classifier.\n",
        " \n",
        "As a counter example, you could have a classifier that was only tested on imbalanced data. In this case, you could have a terrible classifier than only guessing one for every time, and every time you could luckily get imbalanced data in your favour showing an accuracy of a very high percentage. If this was accepted, and used to try and classify real data, the actual result could be as 0% accuracy for a perfectly imbalanced data set completely out of your favour. This would be useless in this case and provide very incorrect information.\n",
        " \n",
        "Imagine an example where there are 95% positive reviews, and 5% negative reviews in a piece of unbalanced data. Even if you set up your classifier to only choose positive reviews, you would still get an accuracy of 95% by completely ignoring the possibility of negative reviews. In real world examples, data provided is not going to be balanced and if you based the likelihood of success on just the accuracy measure given you would fail greatly as imbalanced data that doesn't favour you is provided. In reality you can't get that high of an accuracy without something having gone wrong somewhere\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIS9UpmJNEAp"
      },
      "source": [
        "4) \n",
        "a)  **Construct** a Naive Bayes classifier (e.g., from NLTK).\n",
        "\n",
        "b)  **Compare** the performance of your word list classifier with the Naive Bayes classifier.  **Discuss** your results. \n",
        "\n",
        "[12.5\\%]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "hG4DSeqD50Rz"
      },
      "outputs": [],
      "source": [
        "\n",
        "def normalise(Single_Train,FrqDis): #Normalisation of the data. As i didnt set up a function that normalises in the first step, i needed one that unzipped and zipped back up the information essentially but removed the clutter. It has two input parameters of the single line of data that is going to be normalised IE one review, and a true or false parameter that changes the output of the data to be a frequency distribution. This is used in the naive bayes classifier however for my one if i used the normalise function this could be a false as it does it for it.\n",
        "  list_i = [] #Variable declaration, two lists, one with each word in it and the other with the normalised version.\n",
        "  norm_list_i = []\n",
        "  for i in Single_Train: #For some reason i have to put it into a new list, whenever i tried to just iterate over the information in the format it is in i got an error, the only way i could fix this was by making it a new list completely and removing the type restrictions\n",
        "    list_i.append(i) #each item iterated over is put into a new list\n",
        "  for i in list_i: #iteration over the new list for each item\n",
        "    if i.isalpha() and i not in stop_words and len(i) > 1: #normalisation of the words, if the word fits these parameters it will be filtered through and added to a new list of just the normalised information. If it doesnt fit these it will be discarded.\n",
        "      norm_list_i.append(i) #added to the new list\n",
        "  if FrqDis == True: #takes the parameter of frequency distribution, if it is True it means that i want the data as a frequency distribution and will do so before returning it back\n",
        "    norm_list_i = FreqDist(norm_list_i) #the data is reassigned as FreqDist\n",
        "\n",
        "  return(norm_list_i) #returns the list to its caller\n",
        "\n",
        "def normalise_all(Train,FrqDis): #new function declaration, this takes the entire data set that needs to be normalised and the parameter of frequency distribution to return the data in this manner\n",
        "  list_norm_i = [] #variable declaration of the lists and information needed\n",
        "  norm_i =[]\n",
        "  Type = ''\n",
        "  tup_norm_i = (norm_i,Type) #this is a new varaible of a tuple that holds the information the same way as it is split\n",
        "  for i, Type in Train: #iteration over each item in the data set to be normalised splitting the tuple into reviews and their tags\n",
        "    a = normalise(i,FrqDis) #this returns the data as a normalised version of itself by running the function above\n",
        "    tup_norm_i = (a,Type) #puts the information back into the tuple from whence it came\n",
        "    list_norm_i.append(tup_norm_i) #adds the tuple to the list, so it goes back in the same format that it came in, a list of tuples that contains a list of words and a tag.\n",
        "    \n",
        "  return(list_norm_i) #returns the new set back to the caller\n",
        "\n",
        "def Naive_Bayes_Class(TR_Data,TE_Data): #New function, this is the naive bayes classifier. It takes a training data set in the first position, and a testing data set to work on in the second data set. \n",
        "  accuracy = 0 #Variable declaration\n",
        "  True_Pos = 0\n",
        "  True_Neg = 0\n",
        "  False_Pos = 0\n",
        "  False_Neg = 0\n",
        "  nb_classif = nltk.NaiveBayesClassifier.train(TR_Data) #The creation of the actual classifier, with all the information in order to classify more information as it comes to it. This has many uses and can be manipulated to get the most important information that makes it a decent classifier\n",
        "  #nb_classif.show_most_informative_features() #For example the most informative, this presents a list and the likelihood that they will show up in each type of review and ranks the words from there. This is a better way of doing it in comparison to giving each word the same score and instead rankingly the likleihood they will show up.\n",
        "  Norm_Review,Test_labels = zip(*TE_Data)#gives the two parts of the tuple that is testing data independant names to be iterated through\n",
        "  for label, i in zip(Test_labels,nb_classif.classify_many(Norm_Review)):#This runs the classifier on the testing data after being trained. From there the result is given the variable name i, and the test labels or the actual labels of the reviews is given in labels. These two have the same type of infomration, pos or neg as a string, and thus can be used to compare\n",
        "    if i == label:#if the classifier was correct, the information is passed through this check. IE did new classifier get the item pos for a positive review.\n",
        "      if i == 'neg':#if the review was correct and negative, it adds a mark to the true negatives\n",
        "        True_Neg += 1 #Counted\n",
        "      elif i == 'pos': #If the review was correct and positive,\n",
        "        True_Pos += 1 #True pos counted\n",
        "      accuracy += 1 #In any case where it was correct, a count is added to the accuracy. The closer this is to the length of the testing data the better as it means more of the reviews are classified correctly.\n",
        "    elif i == 'neg': #If the classifier got it wrong, and the item was negative\n",
        "      False_Neg += 1 #False_Neg counted\n",
        "    elif i == 'pos': #If the classifier got it wrong but it was positive\n",
        "      False_Pos += 1 #False_Pos is counted\n",
        "  accuracy = accuracy/len(TE_Data) #Finally the total accuracy of the classifier on a certain data set is measured, by dividing the count of correct information by the total length of the data set in question.\n",
        "  return(True_Pos, True_Neg, False_Pos, False_Neg, accuracy) #return statement, this gives back the information the same as my classifier so it can be put through the same testing functions and get the same class of results. if anything was wrong with the testing parts, errors would be shown in both at the same point.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy, Precision, Recall, F1')\n",
        "print(AC_PR_RE_F1_testing(accuracy_class_testing(classify,10)))\n",
        "print()\n",
        "print(AC_PR_RE_F1_testing(Naive_Bayes_Class(normalise_all(training_data,True),normalise_all(testing_data,True)))) #This is a comparison of the data sets as seen by the top 10 of my wordlist function as well as the naive bayes on the same data."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plfOIcMNA8UI",
        "outputId": "7c152121-cf5e-445a-a1fe-d5f4f7a0e5a0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, Precision, Recall, F1\n",
            "[0.6116666666666667, 0.5739514348785872, 0.8666666666666667, 0.6905710491367862]\n",
            "\n",
            "[0.6916666666666667, 0.6215644820295984, 0.98, 0.7606727037516172]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfuYer9U50Rz"
      },
      "source": [
        "<p>For the case given here, where we use the top 10 values of the word list classifier and all of the naive bayes version, we can see comparable yet different data. In terms of accuracy, the naive bayes is better however as discussed above it is not a fair measure. Because both are measured on the same data set however, the accuracies can be compared between them and the 8% difference pulling up naive bayes makes a large difference in the real results.</p>\n",
        "<p>The precision of the data in both is comparable, however there is a 5% increase for the naive bayes version. Both are in the 60% range, however this is not exactly good as it means that only just over half the time the positives are correct meaning that both are not very pure in their execution.</p>\n",
        " \n",
        "<p>With the recall, the naive bayes classifier is much better than the one I have made. the value of 0.98 means that it finds almost all the positive cases in the data losing only 2%. This is much better than the 0.86 of my classifier, meaning that although both may allow some negative cases as positive cases, for the limits chosen, both are good, however the naive bayes classifier is much better.</p>\n",
        "<p>For the F1 score, we can see a whole 7% increase in the naive bayes, meaning that it has a much better recall and precision than the standard classifier. The higher an F1 score, the better its recall and precision are compared to something else. These being what they are for both mean both are pretty good overall even though the precision of the results weighs them down a bit.</p>\n",
        " \n",
        "Overall, for the data size given the naive bayes classifier is better in every field. This could be changed in many ways, potentially if the word set was increased to a substantial value however this as seen later doesnt have as much influence as I would have liked. A better version may be able to compare better if the weights were changed for the frequency information\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGDXaVDqOSfY"
      },
      "source": [
        "5) \n",
        "a) Design and **carry out an experiment** into the impact of the **length of the wordlists** on the wordlist classifier.  Make sure you **describe** design decisions in your experiment, include a **graph** of your results and **discuss** your conclusions. \n",
        "\n",
        "b) Would you **recommend** a wordlist classifier or a Naive Bayes classifier for future work in this area?  **Justify** your answer.\n",
        "\n",
        "[25\\%]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "9tBhqZtw50R1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ca5cbe-166c-447a-82a3-923ac296652f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.54, 0.5319148936170213, 0.6666666666666666, 0.591715976331361]\n",
            "[0.5866666666666667, 0.5698924731182796, 0.7066666666666667, 0.630952380952381]\n",
            "[0.6166666666666667, 0.5935828877005348, 0.74, 0.6587537091988132]\n",
            "[0.6116666666666667, 0.5739514348785872, 0.8666666666666667, 0.6905710491367862]\n",
            "[0.6416666666666667, 0.5986078886310905, 0.86, 0.7058823529411765]\n",
            "[0.6, 0.5617283950617284, 0.91, 0.6946564885496184]\n",
            "[0.5916666666666667, 0.5533980582524272, 0.95, 0.6993865030674846]\n",
            "[0.5883333333333334, 0.5508637236084453, 0.9566666666666667, 0.6991473812423873]\n",
            "[0.6316666666666667, 0.5817805383022774, 0.9366666666666666, 0.7177522349936142]\n",
            "[0.63, 0.5795918367346938, 0.9466666666666667, 0.7189873417721518]\n",
            "[0.6333333333333333, 0.5816326530612245, 0.95, 0.7215189873417721]\n",
            "[0.6333333333333333, 0.5816326530612245, 0.95, 0.7215189873417721]\n",
            "[0.6366666666666667, 0.5836734693877551, 0.9533333333333334, 0.7240506329113924]\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "Accuracy_List = []\n",
        "Precision_List = []\n",
        "Recall_List = []\n",
        "F1_List = []\n",
        "sample_sizes=[1,2,5,10,20,30,40,50,60,70,80,90,100] #This is the data set i will pass into the classifier to change the length of the wordlist\n",
        "\n",
        "Bayes_Results = AC_PR_RE_F1_testing(Naive_Bayes_Class(normalise_all(training_data,True),normalise_all(testing_data,True))) #This just runs the naive bayes classifier and creates a data set of accuracy, precision, recall and F1 to compare too\n",
        "\n",
        "for i in sample_sizes: #This takes each item out of the sample size, and assigns it to the variable i which incrementally changes\n",
        "  results = AC_PR_RE_F1_testing(accuracy_class_testing(classify,i)) #This line runs the function that creates as a list the 4 pieces, with the classifier being assigned the one i have made and the size of the data set passed into it with the iterator i\n",
        "  print(results) #This prints the results of this function, as a list of the 4 variables\n",
        "  Accuracy_List.append(results[0]) #Each of these lines appends the item to a list of the same item types, this means a list of all the accuracies and ect will be created for each variation in the sample size\n",
        "  Precision_List.append(results[1])\n",
        "  Recall_List.append(results[2])\n",
        "  F1_List.append(results[3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "J1ozKYMa50R1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "42ca3973-2913-410b-afb3-5b558fe376f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.54, 0.5866666666666667, 0.6166666666666667, 0.6116666666666667, 0.6416666666666667, 0.6, 0.5916666666666667, 0.5883333333333334, 0.6316666666666667, 0.63, 0.6333333333333333, 0.6333333333333333, 0.6366666666666667]\n",
            "[0.5319148936170213, 0.5698924731182796, 0.5935828877005348, 0.5739514348785872, 0.5986078886310905, 0.5617283950617284, 0.5533980582524272, 0.5508637236084453, 0.5817805383022774, 0.5795918367346938, 0.5816326530612245, 0.5816326530612245, 0.5836734693877551]\n",
            "[0.6666666666666666, 0.7066666666666667, 0.74, 0.8666666666666667, 0.86, 0.91, 0.95, 0.9566666666666667, 0.9366666666666666, 0.9466666666666667, 0.95, 0.95, 0.9533333333333334]\n",
            "[0.591715976331361, 0.630952380952381, 0.6587537091988132, 0.6905710491367862, 0.7058823529411765, 0.6946564885496184, 0.6993865030674846, 0.6991473812423873, 0.7177522349936142, 0.7189873417721518, 0.7215189873417721, 0.7215189873417721, 0.7240506329113924]\n",
            "[0.6108974358974358, 0.5724808388780993, 0.8764102564102564, 0.6903764635215932]\n",
            "[0.6916666666666667, 0.6215644820295984, 0.98, 0.7606727037516172]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3wUdf7H8dcnPaFDQu/SewldxIIIqDQBQRG7Z/+dWE49T4p6dr07RREVCyAQEBEVQVQUlRqEgPRQhIQWek0gyff3x0xgwUCWZDazu/k8H499kMzMznzGjZ9MZr7zHjHGoJRSKniFuF2AUkop39JGr5RSQU4bvVJKBTlt9EopFeS00SulVJDTRq+UUkFOG70qMkTkqIjUdrsOpQqbNnoVdERkq4icsBt7zquyMaa4MWazH9RXSURmisgOETEiUtPtmlRw00avgtX1dmPPee3w1YZEJOwi35INzAZu8EE5Sv2FNnpVZNhHz3Xsr8uJyFciclhElorI8yLyqz2vpr1smMd7fxKRu+yvbxOR30TkTRHZB4wQkUgReU1EtonIbhEZIyLRudVhjNltjHkHWOr7vVZKG70qukYDx4CKwK3262K0AzYDFYAXgJeAekALoA5QBXjWqWKVKght9CpYzRCRg/ZrhucMEQnFOm0y3Bhz3BizBvjkIte/wxjzljEmE0gH7gEeMcbsN8YcAf4NDHJgP5QqsIs9t6hUoOhjjPn+PPPisH72t3tM236eZc/Hc/k4IAZYJiI50wQIvch1KuUTekSviqI0IBOo6jGtmsfXx+x/YzymVTxnHZ6xr3uBE0BjY0xp+1XKGFPcqYKVKght9KrIMcZkAdOxLqLGiEgDYKjH/DQgFRgiIqEicgdwyQXWlw28D7wpIuUBRKSKiFxzvveISBQQaX8baX+vlE9oo1dF1YNAKWAXMB6YBGR4zL8beBzYBzQGFuSxvn8AycAiETkMfA/Uv8DyJ4Cj9tfr7O+V8gnRB48oBSLyMlDRGHOxo2+U8nt6RK+KJBFpICLNxNIWuBP4wu26lPKFPBu9iIwTkT0i8sd55ouI/E9EkkVkpYi08ph3q4hstF96pKT8SQms8/THgCnA68CXrlaklI/keepGRC7DOpf4qTGmSS7zewIPAT2xbiL5rzGmnYiUBRKBeKwRCsuA1saYA87uglJKqQvJ84jeGDMf2H+BRXpj/RIwxphFQGkRqQRcA8y1byA5AMwFujtRtFJKKe85ccNUFc6+eSTFnna+6RcUGxtratas6UBZSilVdCxbtmyvMSYut3l+cWesiNyDdQs51atXJzEx0eWKlFIqsIjIn+eb58Som1TOvquwqj3tfNP/whgz1hgTb4yJj4vL9ReSUkqpfHKi0c8Ehtqjb9oDh4wxO4E5QDcRKSMiZYBu9jSllFKFKM9TNyIyCbgciBWRFGA4EA5gjBkDzMIacZMMHAdut+ftF5HnOJO5PcoYc6GLukoppXwgz0ZvjBmcx3wDPHCeeeOAcfkrTSmllBP0zlillApy2uiVUirIaaNXSqkgp41eqaIm6xQsnwDHdWxEUaGNXqmiZslY+PIBGN8H0g+5XY0qBNrolSpKju6Bn16C8o1h9xqYOAAyjub9PhXQtNErVZT8MApOHYeBn8ANH0DKUpg8GE6lu12Z8iFt9EoVFam/W+fm290LsXWhcR/o8y5smQ8JQyHzpNsVKh/RRq9UUWAMfPsPKBYHXf5xZnrzQXDtG7BxDky/G7Kz3KtR+YxfpFcqpXxsZQKkLIHeoyGq5Nnz2txpnc757hmYWQx6vQ0hegwYTLTRKxXsMo7A3GehcitoflPuy3R8CE4eg59ehPAY6PkqiBRuncpntNErFex+eR2O7oIbJ1z4SL3LP+DkUVjwFkTEQNeR2uyDhDZ6pYLZvk2wcDQ0HwzV2lx4WRG4+jnryP63/0JECejyeOHUqXxKG71SwWzOPyE0ArqO8G55Eej5Opw8DvOet47sO+QaTqsCiDZ6pYLVxu9hw7fWKZgSFb1/X0iIddE28wTMedo6Zx9/u+/qVD6njV6pYJR5EmY/CWVrQ/v7Lv79oWHQ7wM4dQK+fsRq9s1vdL5OVSi8GkMlIt1FZL2IJIvIk7nMryEiP4jIShH5SUSqeszLEpEV9mumk8Urpc5jyVjYtxG6vwRhkflbR1gEDPwUal4KM+6DNfq/b6DKs9GLSCgwGugBNAIGi0ijcxZ7DfjUGNMMGAW86DHvhDGmhf3q5VDdSqnzOboHfn4Z6lwN9a4p2LrCo2HwZKjSGqbdYZ0OUgHHmyP6tkCyMWazMeYkMBnofc4yjYAf7a/n5TJfKVVYfhhpnXLp/mLey3ojsjjcPBXKN4ApN8PWX51Zryo03jT6KsB2j+9T7GmekoB+9td9gRIiUs7+PkpEEkVkkYj0yW0DInKPvUxiWlraRZSvlDpL6jJYPhHa23k2TokuDbfMgNI14LMbISXRuXUrn3PqPufHgC4ishzoAqQCOaEZNYwx8cBNwH9E5JJz32yMGWuMiTfGxMfFxTlUklJFTHb2mTyby55wfv3FYmHol9a/E/rBzpXOb0P5hDeNPhWo5vF9VXvaacaYHcaYfsaYlsA/7WkH7X9T7X83Az8BLQtetlLqL1YlWLHDXUf8Nc/GKSUrwdCZ1s1U4/tC2nrfbEc5yptGvxSoKyK1RCQCGAScdfldRGJFJGddTwHj7OllRCQyZxmgE7DGqeKVUraMIzB3uHXRtPlg326rTA3ryF5C4NPesH+Lb7enCizPRm+MyQQeBOYAa4EEY8xqERklIjmjaC4H1ovIBqAC8II9vSGQKCJJWBdpXzLGaKNXymnzX7PybHq8UjjJk7F1YOgMyEyHT3vBodS836NcI8YYt2s4S3x8vElM1As9Snlt3yZ4pz006Q993y3cbaf+Dp/0ghIV4PZvoXj5wt2+Ok1EltnXQ/9CQ6eVCnSn82yGF/62q7Syhl4eSrXO2R/fX/g1qDxpo1cqkOXk2XR54uLybJxUowMM/gz2boCJ/SH9sDt1qPPSRq9UoDqdZ3MJtMtHno2TLrkSBnwCO1bApEFW+qXyG9rolQpUS96z82xetHJp3NagJ/QbC38usO6gzcxwuyJl00avVCA6ugd+fgXqdit4no2TmvaHXm/Bph9h6u2QdcrtihTa6JUKTDl5Ntc4lGfjpFa3WMM8139jpV5mZ+X9HuVTmkevVKBJXQbLJ0DHh63x7P6o3d+sRxL+MNJKwLz+f/r8WRdpo1cqkJzOsykPl/n581w7D7Oa/S+vQXgx61qCNntXaKNXKpCsnGLl2fR+x3d5Nk668hmr2S9+14o7vvIZtysqkrTRKxUoMo7A94WUZ+MUEetI/tQxmP+q9UjCzsPcrqrI0UavVKCY/xoc3Q2DPiucPBuniMB1/7HG1v8wEiKKQ7t73K6qSNFGr1Qg2LcJFo6GFjdD1VzjTPxbSCj0HWONFPr2cesCbatb3K6qyAigwwKlirA5T0NYFFzlQp6NU0LDYcBH1l20Mx+CVdPcrqjI0EavlL/bOBc2zIYuj1spkYEsLBJunAjVO8AXf4N1s9yuqEjQRq+UP8vJsylXx/08G6dExMBNU6BiM5h6K2ya53ZFQc+rRi8i3UVkvYgki8iTucyvISI/iMhKEflJRKp6zLtVRDbar1udLF6poLfkPdiXbN0B6w95Nk6JKglDPodydWHyTfDnQrcrCmp5NnoRCQVGAz2ARsBgEWl0zmKvAZ8aY5oBo4AX7feWBYYD7YC2wHARKeNc+UoFsSO74aeX7Tybbm5X47yYstZTqkpWhs8GWg8xUT7hzRF9WyDZGLPZGHMSmAz0PmeZRsCP9tfzPOZfA8w1xuw3xhwA5gLdC162UkXAD6OsR/X5Y56NU4qXtx42Hl0aJvSD3fqkUV/wptFXAbZ7fJ9iT/OUBPSzv+4LlBCRcl6+FxG5R0QSRSQxLS3N29qVCl4py2DFBGh/n//m2TilVBWr2YdFWQ8b35vsdkVBx6mLsY8BXURkOdAFSAW8jqwzxow1xsQbY+Lj4uIcKkmpAJWdDd8+AcUr+H+ejVPK1rKavcm2HjZ+4E+3Kwoq3jT6VKCax/dV7WmnGWN2GGP6GWNaAv+0px305r1KqXOsnAKpidB1RGDk2Tglrh7c8gWcPGod2R/e6XZFQcObRr8UqCsitUQkAhgEzPRcQERiRSRnXU8B4+yv5wDdRKSMfRG2mz1NKZUbzzybZoPcrqbwVWoGN38Ox9JgfB84ttftioJCno3eGJMJPIjVoNcCCcaY1SIySkR62YtdDqwXkQ1ABeAF+737geewflksBUbZ05RSuZn/qpVn0+PVwMqzcVK1NjB4MhzYCuP7womDblcU8MQY43YNZ4mPjzeJiYlul6FU4du3CUa3g2YDoc87blfjvo1zYdJgqNzSOqUTWdztivyaiCwzxuQahFREDxmU8kOznwr8PBsn1b0a+o+znqg1aZAViKbyRRu9Uv5g41zYOAe6PBH4eTZOatQL+rwLW3+FhFutSAh10bTRK+W2s/Js7nW7Gv/T/Ea47k3rF+H0uyAr0+2KAo7m0SvltsVjrDybm6cFV56Nk+Jvh1PHrbjm8AetRykW1YvV+aCNXik3HdkNP78Cda+xzkkXki17j1G9bAyhIQH0sO4OD1jPn533gvVIwmtf14eNe0l/JSrlph9GWnk23Qsvz+arpB1c8dpP3DdhGemnvL6B3T9c9jh0+j9I/BDm/gv8bNSgv9JGr5RbUpbBionQ4X4od0mhbHL34XSemfEHVUpHM3ftbm7+YDEHjgXQBU4R6DoS2twFC96y/hpSedJGr5QbXMizMcbwxLSVZGRmMf7Otoy+qRWrUg9xw5gFbN9/vFBqcISIdUNZ85vgp39bDV9dkDZ6pdywcrKdZzMSIksUyiYnLt7GzxvSeLpnQ2rHFadn00qMv6Mte49k0O/dBazecahQ6nBESAj0egsa9YHvnoGlH7pdkV/TRq9UYUs/DN+PgCrx0OzGQtnk1r3HeOGbtXSuG8uQdjVOT29XuxzT7utIeIhw43uL+GVjAMWEh4ZBv/etC9nfPApJk92uyG9po1eqsJ3Os3mlUIYIZmUbhiWsIDxUeKV/M0LOGWlTr0IJpt/fiaplorn9o6VM/z3F5zU5JiwCBn4KtTrDjPtgzZduV+SXtNErVZj2JsOid6HFEKjaulA2+d78Tfy+7SDP9WlCpVLRuS5TsVQUCfd2oE3NsgxLSOLdnzbhbzlY5xUeBYMmQdU2MO1O2PCd2xX5HW30ShWmOU/beTbPFsrm1uw4zJtzN3Bt00r0al75gsuWjArn4zva0Kt5ZV6evY4RM1eTlR0gzT6yONyUABUaQcItsGW+2xX5FW30ShWWDd9Zt/Ff/o9CybPJyMxiWMIKSsdE8FyfJogXNxdFhoXynxtbcM9ltflk4Z/cPzGAxtpHl4YhX0CZmvDZINi+xO2K/IY2eqUKw+k8m7rQ9m+Fssk35m5g3a4jvHxDU8oW8z5aISREeLpnQ569rhHfrdnNkA8Wc/B4gIy1L1YOhn5pPXR8Qn/YmeR2RX7Bq0YvIt1FZL2IJIvIk7nMry4i80RkuYisFJGe9vSaInJCRFbYrzFO74BSAWHxu7B/k3UHbCHk2Szdup+x8zczuG01rmyQv78e7ri0Fm8PbsXKlEPc8O4CUg4EyFj7EhXh1pnWsNXxfSFtvdsVuS7PRi8iocBooAfQCBgsIo3OWewZrCdPtcR61KDnUxM2GWNa2C+N5lNFz5Hd8POrUK97oeTZHM3IZFjCCqqVieGZa8/9X/XiXNusEp/e2Za0Ixn0eyeAxtqXrm41+5Aw+KQX7N/sdkWu8uaIvi2QbIzZbIw5CUwGep+zjAFynmJcCtjhXIlKBbicPJtr/l0om3vhm7WkHDjB6wObUyyy4LmF7e2x9qH2WPvfkgPkOa7lLoFbZkDWSfikNxwKoGGjDvOm0VcBtnt8n2JP8zQCGCIiKcAs4CGPebXsUzo/i0jn3DYgIveISKKIJKalBdANG0rlJSXRzrN5oFDybOat28OkJdu457LatKlZ1rH1WmPtO1KldDS3fbSEGctTHVu3T1VoBLdMh/SD1pH9kd1uV+QKpy7GDgY+NsZUBXoC40UkBNgJVLdP6QwDPhORkue+2Rgz1hgTb4yJj4uLc6gkpVx2Os+mIlz2mM83d+DYSZ74fCX1K5Rg2NX1HF9/pVLRJNzbgdY1yvD3KSsY83OAjLWv3BJungpHdsL4PnB8v9sVFTpvGn0qUM3j+6r2NE93AgkAxpiFQBQQa4zJMMbss6cvAzYBzv8EKuWPVk62nnfadYTP82yMMTwz4w8OHj/JGzc2JzIs1CfbKRUdzid3tOW6ZpV46dt1jPxqTWCMta/eHgZPsh7APqGfFUNRhHjT6JcCdUWklohEYF1snXnOMtuAqwBEpCFWo08TkTj7Yi4iUhuoCxTtqyKqaEg/DHOHW3drFkKezcykHXyzaid/71qPxpVL+XRbkWGh/G9QS+7uXIuPF2zlgYm/B8ZY+9qXw8BPYNcq+Gyg9RCTIiLPRm+MyQQeBOYAa7FG16wWkVEi0ste7FHgbhFJAiYBtxnrb7rLgJUisgKYBtxrjCl6fzepomf+q3BsD/R42ed5NjsPneBfM/6gdY0y3NulcHLtQ0KEf17biH9d14g5a3Zxy4cBMta+fg/oNxa2L4bJN0NmhtsVFQrxt3Ns8fHxJjEx0e0ylMq/vcnwTnvrSL7PaJ9uyhjD0HFLSNx6gG//rzM1Y4v5dHu5+XrlDoZNSaJ6uRg+uaMtVUrnnqfjV5ZPhC/vh/rXWkf5oeFuV1RgIrLMGBOf2zy9M1Ypp815CsKjoetwn29qwqI/+WXjXv55bUNXmjzAdc0q8+mdbdl9OJ1+7/zGmh0BcP675c3Q8zVY/w188TfIDoBTTwWgjV4pJ22YAxu/gy5PWLfh+9CWvcd4YdZaLqsXx83tqvt0W3lpX7sc0+7tiCAMfG9hYIy1b3u39eCXPz6Hrx62RkkFKW30Sjkl8yTMfqpQ8mwys7J5ZMoKIsNCeeWGZl4Flvla/Yol+OKBM2Ptv1wRAGPtL/07XPYELJ9g/SXmZ6eynaKNXimnnM6zecnneTZjft7Eiu1WxnzFUlE+3dbFyBlr36p6Gf5v8greC4Sx9lc8De0fgMVj4Mfn3K7GJ7TRK+WEI7vg51fsPJuuPt3UH6mH+M/3G7m+eeU8M+bdUCo6nE/vbMu1zSrxYiCMtReBa16A1rfBL6/D/NfcrshxBQ/CUErB9yOtTBUf59mkn7Iy5ssWi+C53o19uq2CiAwL5a1BLalYMooPf93CniPpvDGwBVHhvrmRq8BE4No34ORx66g+oji0D54MRm30ShVUSiIkfQad/u7zPJs35m5gw+6jfHx7G0rH+D7uuCBCQoR/XdeISqWieP6btew9soT3h8ZTKsZPhzKGhEKfd+HUcZj9D4iIgVZD3a7KEXrqRqmCyM6GWY8XSp7Nos37eP+XzdzcrjqX1/ftiB4n3dW5Nv8b3JIV2w/Sf8wCUg+ecLuk8wsNg/7joE5XmPkwrJrmdkWO0EavVEEkTYIdv8PVI32aZ3Mk/RSPTU2ietkYnu7Z0Gfb8ZVezSvzyR1t2WWPtV+704/H2odFwsDxUKMTTL8H1n3jdkUFpo1eqfxKPwzfj7DybJoO9Ommnv96LTsOnuANhzLm3dDhknJMvbeDNdZ+zEIW+PNY+4gYuGmylXw59TZI/sHtigpEG71S+TX/FTiW5vM8m+/X7GZK4nbu7XIJrWs4lzHvhgYVSzL9/o5UKh3FrR8tYWaSHz+jKLIEDJkGsfWtXJw/F7hdUb5po1cqP/ZuhEVjrFvpq7T22Wb2Hc3gyekraVipJH/vGhwJ35VLRzP13o60rF6Ghyct5/35m/13rH10GbjlCyhVFSYOtGKnA5A2eqXyY7adZ3OV7/JsjDH884s/OHwikzcGNiciLHj+dy0VHc6nd7Tl2qaVeGHWWkZ9vYZsfx1rXzzOev5sTFkY3w92/eF2RRcteH5ylCosG+ZA8lzo8g+f5tl8sTyV2at3MaxbPRpW+suD2QJeVHgobw1uyR2davHRb1t5aNJy/821L1nZavbhMdZTqvYmu13RRdFGr9TFyMzwyLO5x2eb2XHwBMO/XE2bmmW4u3Ntn23HbSEhwrPXN+KZaxvyzaqdDB23hEPHT7ldVu7K1IShX1p5OJ/2ggN/ul2R17xq9CLSXUTWi0iyiDyZy/zqIjLPfgj4ShHp6THvKft960XkGieLV6rQLfJ9nk12tuHxaUlkGcPrA1oQGuJ+YJmv5Yy1X77tAP3HLGCHv461j6tnNfuTx6xmf9iPLyZ7yLPR248CHA30ABoBg0Wk0TmLPYP15KmWWI8afMd+byP7+8ZAd+CdnEcLKhVwjuyynhxVr4dP82w+XbiV35L38a/rGlG9XIzPtuNvTo+1P5ROv3cWsG6Xn461r9gEhkyHY3vh097Wv37OmyP6tkCyMWazMeYkMBnofc4yBsg5iVgKyPk11xuYbD8kfAuQbK9PqcDz/Qg7z+YFn20iec9RXvx2HVfUj2NQm2o+246/6nhJLAn3dsBgGPDuQhZs8tMmWrU13JQAB7db5+xPHHC7ogvyptFXAbZ7fJ9iT/M0AhgiIinALOChi3ivUv4vJdG6C7bDAz7Ls8nMyubRhBVER4Tysp9kzLuhYaWSTL+/ExVLRXHbuKX+O9a+ZicYNAH2rIOJAyDjiNsVnZdTF2MHAx8bY6oCPYHxIuL1ukXkHhFJFJHEtLQ0h0pSyiGeeTadH/XZZkbP20RSyiFe6NOU8iX9J2PeDVVKRzPt3o60qFaahyct54NfNrtdUu7qdIUBH0Hq7zBpMJzyz2sL3jTjVMDzb8iq9jRPdwIJAMaYhUAUEOvlezHGjDXGxBtj4uPi4ryvXqnCkPSZnWczymd5NitTDvLWjxvp3aIy1zar5JNtBJpSMVaufc+mFXn+m7U8569j7RteD33HwNZfYcot1pPG/Iw3jX4pUFdEaolIBNbF1ZnnLLMNuApARBpiNfo0e7lBIhIpIrWAusASp4pXyufSD1tZ81XbQjPf5NlYGfNJxBaPZFSvJj7ZRqCKCg/l7cGtuL1TTT78dQsPTV5ORqYfjrVvNhCu/491f8Xnd0JWptsVnSXPdCRjTKaIPAjMAUKBccaY1SIyCkg0xswEHgXeF5FHsC7M3mase5pXi0gCsAbIBB4wxvjhp6TUeeTk2dw0xXo4hQ+8Omc9yXuOMv7Otv6b1e6ikBDhWTvX/t+z1rH3SAZjh8ZTKtrP/lu1vs16cMmcp+DLB6xsex9mIF0M8beMifj4eJOYmOh2GUpZeTbvtIfmg6H32z7ZxIJNe7np/cUM7VCDUb31aD4vX65I5bGpSdSKLcbHt7elculot0v6q/mvwo/PQ/wd1lOrCumiuogsM8bE5zbPP37dKOVvjIHZT1q3vPsoz+Zw+iken7qSWrHFeLJHA59sI9j0blGFT25vy86DfjzWvvNjcOkjkDgOvnvG+llymTZ6pXKzYQ4kfw+XP2mFWvnAqK/WsPPQCV4f2JyYiMDMmHdDxzoeY+3HLGThpn1ul3Q2EevgoO09sPBt+OkltyvSRq/UX2RmWOdZY+v5LM9mzupdTFuWwgNX1KFV9TI+2UYwyxlrX6FkFLeOW8LXK/1srL0IdH8ZWgyBn1+C3/7rajna6JU616J3Yf9m6P4ihDp/wW/v0Qyenr6KxpVL8tCVdR1ff1FhjbXvQPNqpXjwMz8cax8SAr3+B437wdxnYcn77pXi2paV8kc5eTb1e1o3wzjMGMNT01dxJCOTN29sEVQZ824oHRPB+Dvb0aOJNdb+eX8bax8SCv3GWvlIsx6DFZ+5U4YrW1XKX/k4z+bz31OZu2Y3j3erT70KvnuYeFESFR7K2ze14raONfng1y087G9j7UPDYcDHUPtya9jl6hmFXoI2eqVybF96Js+mrPMZ8CkHjjNi5mra1irLHZfWcnz9RVloiDD8+kY81aMBX6/cya3jlnDohB/l2odHwaDPrBvvPr/TuthfiLTRKwVWns23T0CJStbwOMdXb3hsahLGGF4f0LxIZMwXNhHhb10u4b+DWrDszwMMHLOQnYf8KHsmohjcnAAVmlhRCZt/LrRNa6NXCs7k2XQdCZHFHV/9Rwu2smjzfoZf35hqZYtOxrwbereowse3tyX14An6vbOADbv9KFUyqpT1sPFyl1ghaNsWF8pmtdErlX7IOjfvozybjbuP8PLsdXRtWJ4B8VUdX7/6q051Ykn4Wweysg39313Aos1+NNY+pizcMgNKVLDijXes8PkmtdEr9fMr1lOCer7i+O3qp7KyGZaQRPHIMF7sV3Qz5t3QqHJJpt/fkbgSkQz90M/G2peoAENnQlRJGN8X9qz16ea00auiLW0DLB4DLYdA5ZaOr/7tH5NZlXqIF/o0Ia5EpOPrVxdWtUwMn9/XkWZVS/HQpOV8+OsWt0s6o3Q16/mzoeHwaR/Yt8lnm9JGr4ouY6w7YH2UZ7Ni+0HenpdMv5ZV6NFUM+bdUjomggl3teOaRhV57us1vPCNH421L3eJ1eyzTlrPnz24Pe/35IM2elV0+TDP5sTJLIYlrKB8iUiG92rs6LrVxYsKD2X0za24tUMN3v9lC/83ZYX/jLUv39C6QJt+GD67EbKdr0uTlFTRlJlhpVPG1vdJns3Ls9exOe0YE+9q53+56UVUaIgwoldjKpWO5qVvrVz794a2pmSUH3w+lVvAkGnWowhDQh1fvR7Rq6Jp0TtwYItP8mx+S97Lxwu2clvHmnSqE+voulXBiAj3drmEN29sztKt+xk4ZiG7DqW7XZalWluo3cUnq/aq0YtIdxFZLyLJIvJkLvPfFJEV9muDiBz0mJflMe/cRxAqVfgO74T5r9l5Nlc5uupDJ07x2NQkascV4x/dNWPeX/VtWZWPbm9DyoET9HvnN/8aa+8DeTZ6EQkFRgM9gEbAYBFp5LmMMeYRY0wLY0wL4C1gusfsEznzjDG9HKxdqfzxYZ7NyJmr2fFjPGIAABwrSURBVHMkgzcGtiA6wvk/wZVzOteNY8rf2nPKHmu/2J/G2jvMmyP6tkCyMWazMeYkMBnofYHlBwOTnChOKcdtXwIrJ0OHBx3Ps/l21U6mL0/lgSvq0KJaaUfXrXyjceVSTL/PGmt/y4dLmLVqp9sl+YQ3jb4K4DnmJ8We9hciUgOoBfzoMTlKRBJFZJGI9DnP++6xl0lMS0vzsnSlLtJZeTaPOrrqPUfSefqLVTStUoqHrqzj6LqVb1Ure2as/QOf/c5Hv/nRWHuHOH0xdhAwzRjjOT6ohv3A2puA/4jIJee+yRgz1hgTb4yJj4vzzWPblGLFRNixHK4e5WiejTGGp6ev4tjJLN68sTnhoTrGIdDkjLXv1qgCI79aw4uz1vrPWHsHePMTmQpU8/i+qj0tN4M457SNMSbV/ncz8BPg/O2HSuUl/RD8MBKqtYOmAxxd9dTEFL5fu4d/dG9AnfKaMR+oosJDeefm1tzSvgbvzd/M3/1prH0BedPolwJ1RaSWiERgNfO/jJ4RkQZAGWChx7QyIhJpfx0LdALWOFG4UhclJ8+mx8uO5tls33+ckV+tpn3tstzesaZj61XuCA0RRvVuzBPd6zMzaQe3f7SUw+l+lGufT3k2emNMJvAgMAdYCyQYY1aLyCgR8RxFMwiYbIzx/HunIZAoIknAPOAlY4w2elW4cvJsWt3iaJ5NVrbh0alJiAivDWhOiGbMBwUR4f7L6/DGwOYs2WKNtd992E/G2ueTnN2X3RcfH28SExPdLkMFC2Ngwg2QkggPLXM06uD9+Zt5YdZaXu3fjAHx1fJ+gwo4v2xM497xyygdE8HHt7ehrh8//lFEltnXQ/9Crxqp4LZhNmz6wfE8m/W7jvDqnPV0a1SB/q01Yz5YWWPtO3AyK5sb3l3Aki373S4pX7TRq+CVmQGzn7LzbO52bLUnM7MZlrCCElFh/LtfU82YD3JNqlhj7WNLRDLkw8V8G4Bj7bXRq+C1cLSVZ9PjJUfzbN76cSOrdxzmxX5NiS2uGfNFQbWyMXx+b0eaVC7J/Z/9zscBNtZeG70KTqfzbK6FS650bLW/bzvA6HnJ9G9dlW6NKzq2XuX/yhSL4LO723N1wwqMCLCx9troVXD6fgRkn4JrnndslcdPZvJoQhKVSkXz7PWN8n6DCjpR4aG8O+TMWPthCSs4mZntdll50jx6FXxy8mw6P+pons1L365jy95jfHZ3O//IMFeuyBlrX7FUFK/OWU/a0QzGDGlNCT/+mdAjehVcsrNh1uNWns2lwxxb7fwNaXy68E/uvLQWHS/RjPmiTkR44Io6vD6gOYs372fge4v8eqy9NnoVXFZMgJ0r4OrnHMuzOXT8FE9MW0md8sV5/Jr6jqxTBYcbWldl3G1t2LbvGP3eWUDyHv/MtddGr4JH+iH4YRRUaw9N+zu22uEz/2Dv0QzeHNiCqHDNmFdnu6yeNdY+IzObG95dyNKt/jfWXhu9Ch4+yLP5ZuVOZqzYwUNX1qVp1VKOrFMFnyZVSvHF/R0pVyyCmz9YzOw//GusvTZ6FRzS1tt5NkOtBy07YM/hdP45YxXNq5bi/iv+kq6t1FmqlY1h2n3WWPv7Jv7OJwu2ul3SadroVeAzBmY/CeHF4KpnHVql4R+fr+TEySxeH9hCM+aVV8oWi2DiXe25qkEFhs9czUvfrvOLsfb606sC3/pvYdOPVp5NMWdGxExeup1569N4qkcD6pR37iElKvhFR4QyZkgrbm5XnTE/b+LRqUmuj7XXcfQqsGVmwJynHc2z2bbvOM99vYZOdcoxtENNR9apipaw0BCe79OEyqWjrbH2RzJ4d0gr18ba6xG9CmwO59lYGfMrCA0RXu2vGfMq/3LG2r/avxmLNu9zday9V41eRLqLyHoRSRaRJ3OZ/6aIrLBfG0TkoMe8W0Vko/261cniVRF3eIeVZ9PgOsfybN7/ZTNLtx5gZK/GVC4d7cg6VdE2IL4aH97Whj9Pj7U/Wug15NnoRSQUGA30ABoBg0XkrKAPY8wjxpgWxpgWwFvAdPu9ZYHhQDugLTBcRMo4uwuqyPp+BGRnQjdn8mzW7jzMG99toHvjivRtWcWRdSoF0KVeHFPu6UBGZhb9xywgsZDH2ntzRN8WSDbGbDbGnAQmA70vsPxgzjwg/BpgrjFmvzHmADAX6F6QgpUCYNtiWDkFOj4IZWsVeHUZmVk8MmUFJaPDeaFvE82YV45rWrUU0+/rRJmYnLH2uwpt2940+irAdo/vU+xpfyEiNYBawI8X814RuUdEEkUkMS0tzZu6VVGWnQ3fPgElKjuWZ/Pf7zeybtcRXurXlHKaMa98pHq5GD6/ryMNK5XkvonL+HTh1kLZrtMXYwcB04wxWRfzJmPMWGNMvDEmPi7Ouce9qSB1Os9mlCN5Nsv+3M+YnzdxY3w1ujaq4ECBSp1f2WIRTLrbGmv/7JereXn2Onz97G5vGn0q4Pnk46r2tNwM4sxpm4t9r1J5O3EQvh/pWJ7NsYxMhiUkUbl0NM9c19CBApXKW85Y+5vaVefdnzbxaIJvx9p70+iXAnVFpJaIRGA185nnLiQiDYAywEKPyXOAbiJSxr4I282e5rysTJh8Myx5H47u8ckmlB/4+RU4vg96vuJIns2/Z61l2/7jvDaguV/niavgExYawgt9mvBYt3pMX57KnZ8s5WhGpk+2lWejN8ZkAg9iNei1QIIxZrWIjBKRXh6LDgImG4+/QYwx+4HnsH5ZLAVG2dOcd2QH7N0Asx6D1+vDx9fB0g/hqJ7zDxpp62HJe1aeTaXmBV7dvPV7mLh4G3ddWov2tcs5UKBSF0dEePDKurzavxkLNu1jyAeLyfJBZIL4+tzQxYqPjzeJiYn5e7MxsGcNrJ4Bq6fDvmSQEKjZGRr3gYa9HLtFXhUyY2BCP0hZBg//XuDP8eDxk3R7cz6lY8KZ+eClGj+sXPfT+j0cOnGK3i3yN7RXRJYZY+JzmxdcEQgiUKGx9briadi9GlZ/Yb2+fgS+eQxqdYbGfaHB9VBMj+ICRk6eTfeXHPll/a8vV7P/2EnG3dZGm7zyC5fXL++zdQfXEf35GAO7VsGaGVbT378ZJBRqXWY1/YbXQ0xZZ7epnHMqHd5pB2FRcO+vBY46mJm0g4cnLeexbvV48Mq6DhWplLuKzhH9+YhApWbW68p/wa6VZ470v3rYOtqvfbl9pH+tNn1/s2g0HNgKt8wocJPfdSidf834gxbVSnNvF82YV0VD0TiiPx9jYGfSmaZ/8E8ICTu76UdrYoOrDu+At+Lhkitg0MQCrcoYw60fLWXJln3MergzteM0flgFDz2iPx8R62lElVtA1xGwY/mZ0ztfPgBf/d1qMI37Qv2eEF3a7YqLnrnDHcuzmbh4G/M3pDGqd2Nt8qpIKdqN3pMIVGllvbqOhB2/20f6M2DjdxASbiUkNu4L9Xto0y8M2xbBqgTo/FiB82y27j3GC9+spXPdWG5pX8OhApUKDNrocyMCVVpbr6ufg9RlHk1/DoRGnN30o/Sh0Y7LzjqTZ9O5YHk2WdmGYQkrCA8VXunfTAPLVJGjjT4vIlA13np5Nv01M2DDbKvp1+lqNf163SGqpNsVB4flE6zrJzd8CBHFCrSq9+Zv4vdtB/nvoBZUKqUZ86ro0UZ/MUJCoFob69XteUhNPHOkv34WhEaeafr1u0NkCbcrDkwnDsIPo6B6B2hyQ4FWtXrHId6cu4Frm1aiV/PKDhWoVGDRRp9fISFQra316vYCpCyxGv6aGbD+G6vp1736zJG+AymLRcbPL1t5Nj2mFyjPJiMzi2FTkigdE8HzfTRjXhVd2uidEBIC1dtbr2v+DdsX26d3voR1X1s3+uQ0/brXaNO/kLT1sGQstL61wHk2b8zdwPrdR/jotjaUKRbhUIFKBR5t9E4LCYEaHaxX9xetkSNrZlhNf+1XEBYN9brZTb9bgc8/BxVjYPaTEF7MurGtAJZu3c/Y+ZsZ3LY6VzTw3a3lSgUCbfS+FBIKNTtZr+4vwbaFZ47013wJ4TFWsz/d9GPcrthd62fZeTYvFyjP5mhGJsMSVlCtTAzPXKsZ80ppoy8sIaFQ81Lr1eMV+HOB1fTXzrSO+MNjrHP5jftAnauLXtM/lQ5znoa4BtDmzgKt6oVv1pJy4AQJf+tAsUj9EVdK/y9wQ0iolaJZq7Pd9H+zm/5XVrxyeDFr1E7jvtYonvAiMCRw4duO5Nn8uG43k5Zs429datOmpmYWKQVeZt2ISHfgv0Ao8IEx5qVclhkIjAAMkGSMucmengWsshfbZozpde57PRVq1o2/ycqEP3+1T+/MhBP7IaK4dVNWoz52049yu0rnOZRns/+YlTEfWzyCLx/sRGSYxg+roqNAWTciEgqMBq4GUoClIjLTGLPGY5m6wFNAJ2PMARHxvPp1whjTokB7UFSE2oFqtS+Hnq/D1vnWkM21X8GqqRBRwmr6jftad+YGS9PPybO55oV8r8IYwzMzVnHoxEk+vaOtNnmlPHhz6qYtkGyM2QwgIpOB3sAaj2XuBkYbYw4AGGP0oa0FFRpmNfNLroRrX4ct88+c3lmVYDX9Bj3PNP2wSLcrzp+cPJvLHocyNfO9mplJO5i1ahdPdK9Po8p6d7JSnrxp9FWA7R7fpwDtzlmmHoCI/IZ1emeEMWa2PS9KRBKBTOAlY8yMczcgIvcA9wBUr179onagSAgNhzpXWa/r3oQtP9tN/2tYOQUiS1qRyo37Qu0rICxAxozn5NmUrAKXPpLv1ew8dIJ/zfiD1jXK8LfLNGNeqXM5dTE2DKgLXA5UBeaLSFNjzEGghjEmVURqAz+KyCpjzCbPNxtjxgJjwTpH71BNwSk03DpXX6crXOvR9Nd9DUmTILKUR9O/3L+b/vLxBc6zyc42PDFtJaeyDK8PaE5oiN79qtS5vGn0qUA1j++r2tM8pQCLjTGngC0isgGr8S81xqQCGGM2i8hPQEtgE6rgwiKsO27rXg2Z/4HNP9lN/xtI+sxK1WxwvTVks1YX/2r6DuXZTFj8J79s3MvzfZpQM1ZvPlMqN940+qVAXRGphdXgBwE3nbPMDGAw8JGIxGKdytksImWA48aYDHt6J+AVx6pXZ4RFWHfc1usGmRmwaZ41Pn/tTFgxAaJKQ8PrrCP9Wl0K/Ei+Avv5ZTi+H3q8nO88m81pR/n3rLV0qRfHze30lJ9S55NnozfGZIrIg8AcrPPv44wxq0VkFJBojJlpz+smImuALOBxY8w+EekIvCci2UAI1jn6NefZlHJKWKQ1Dr9+d7vp/2inbH5pxf9Gl4EGOU3/ssJv+nvWweL3oPVt+c6zyczKZlhCEpFhoZoxr1QeivYzY4uaU+lnmv76WXDyKESXhYbXW02/ZmdrtI8vGQPj+1pP8HpoORQrl6/VvP3jRl77bgNvDW7J9Ro/rJQ+M1bZwqOsIZkNesKpE5D8g9X0V02D3z+BmHJnmn6NS33T9NfPgs3z7Dyb/DX5P1IP8Z/vN3J988ra5JXygh7RK7vpf28f6c+GU8cgJhYa9bLuyK15qRXbUODtpMPotlauz72/5OuUUfqpLK5/61cOnTjFd49cRukYP7rArJSL9IheXVh4tHUk3/B6OHkckudad+QmTYbEcVAsDhr2so/0O+a/6S98Gw7+CUO/zPd1gde/W8/GPUf5+PY22uSV8pI2enW2iBho1Nt6nTwOG7+zjvRXfAaJH0Kx8ta8xn2soZHeNv1DqfDL69Yvk9qX56u0RZv38cGvWxjSvjqX19eMeaW8pY1enV9EjNXQG/eBk8fONP3lE2Dp+1C8gt30+0K19tZDV87n++HWnbDdns9XKUfST/HY1CSql43h6Z6aMa/UxdBGr7wTUcxq6I37QsZR2DjHavq/f2o9+q94RY+m3+7spr9tkRXKVoA8m+e/XsuOgyeYem8HYiL0x1api6H/x6iLF1ncupu1yQ2QcQQ22E1/2cew5D0oUcm6iNu4L1RpDbMeL1CezfdrdjMlcTv3X34JrWtoxrxSF0sbvSqYyBLQtL/1yjhijdpZ/YV1EXfxu9YduekH851ns+9oBk9OX0nDSiX5e9d6PtgBpYKfNnrlnMgS0GyA9Uo/DBvsph9VKl95NsYYnv5iFYdPZDLhruZEhF3gGoBS6ry00SvfiCoJzQZar3z6Ynkqc1bv5qkeDWhQUTPmlcovPURSfmnHwRMM/3I1bWqW4a7Otd0uR6mApo1e+Z3sbMPj05LIMobXB7TQjHmlCihoGn12tuHNuRv4ZuVONqcdJTvbv6IdlPc+WbiV35L38a/rGlG9XIzb5SgV8ILmHP2uw+m8PS+ZLLvBR4eHUr9iCRpVLknDSiVpVKkE9SuWpHhk0OxyUErec5SXvl3HFfXjGNSmWt5vUErlKWi6XuXS0aweeQ3Je46yZudh1tqvb1bu5LPF204vV6NcDA0rWs2/YaUSNKxUkqplojXP3A+cyspmWMIKYiJCefkGzZhXyileNXoR6Q78F+vBIx8YY17KZZmBwAjAAEnGmJvs6bcCz9iLPW+M+cSBunMVFR5KkyqlaFKl1Olpxhh2Hko/3fjX7jzC2p2HmbNmFznBnSWiwuzmX8L+BVCS+hVLEBXuQGKj8to78zaxMuUQ79zcivIlo9wuR6mgkWejF5FQYDRwNdazYZeKyEzPJ0WJSF3gKaCTMeaAiJS3p5cFhgPxWL8AltnvPeD8rpy3fiqXjqZy6Wiualjh9PTjJzNZv+vI6ca/dudhpi1L4djJLABCBGrFFjvd+BvZ/1YoGalHmj6wMuUgb/24kT4tKtOzaSW3y1EqqHhzRN8WSDbGbAYQkclAb8DzkYB3A6NzGrgxZo89/RpgrjFmv/3euUB3YJIz5edfTEQYLauXoWX1MqenZWcbth84ztqdh1lj/wJYsf0gX6/ceXqZMjHhp5t/zumfOuWLExmmR//5lX4qi2EJScQWj2RkryZul6NU0PGm0VcBtnt8nwK0O2eZegAi8hvW6Z0RxpjZ53lvlXxX62MhIUKNcsWoUa4Y3ZucOao8nH6KdR5H/mt3Hmbi4j9JP5UNQFiIUKd88bPO+zesVJLY4pFu7UpAeWX2epL3HGX8nW0pFePyQ8uVCkJOXYwNA+oClwNVgfki0tTbN4vIPcA9ANWrV3eoJOeUjAqnba2ytK11JlArK9uwZe+xs5r/wk37+GJ56ull4kpEnm7+Oad+ascWIyw0aEa1FtiCTXsZ99sWhnaoQee6cW6Xo1RQ8qbRpwKe49yq2tM8pQCLjTGngC0isgGr8adiNX/P9/507gaMMWOBsWA9StDL2l0Vah/F1ylf/Kznlh44dtI+9XPmwu9Hm/ZxMss6+o8IC6FeheIeI3+s8/9F8Uj2cPopHp+6ktqxxXiqh2bMK+Ur3jT6pUBdEamF1bgHATeds8wMYDDwkYjEYp3K2QxsAv4tIjknwrthXbQNWmWKRdCxTiwd68SennYqK5tNaUfPGvUzb/0epi5LOb1M5VJRfzn3X7NcMUKC+K7QUV+tYeehE3x+X0eiI/Qah1K+kmejN8ZkisiDwBys8+/jjDGrRWQUkGiMmWnP6yYia4As4HFjzD4AEXkO65cFwKicC7NFSXhoCA0qlqRBxZL0bXlm+p4j6WeN+lm78zA/bUj7y01fOTd8NaxUkgaVguOmrzmrdzFtWQoPXVnnrAviSinniTH+daYkPj7eJCYmul2Ga9JPZf3lpq+1O49w6MSp08tULxtz1kXfRgF209feoxlc8+Z8KpaK4ov7O2n8sFIOEJFlxpj43OYF/qFhkLmYm76+W7P7zE1fkWE08Gj+DSuVpH6FEn53SsQYw1PTV3EkI5NJN7bQJq9UIdBGHwAu5qav6b+ncjTjT8A/b/qatiyFuWt288+eDalXoYQrNShV1GijD2CBdtNXyoHjjPxqDe1qleXOS2v5dFtKqTO00QcZf73pKzvb8NjUJIwxvDageVCPJlLK32ijLyLcvunrowVbWbR5P6/c0IxqZTVjXqnCpI2+CCusm7427j7Cy7PX0bVheQbEVy2UfVNKnaGNXv2Fkzd9VSkTzbCEJIpHhvFiP82YV8oN2uiVV/J701d4qHAqyzBmSCviSmjIm1Ju0EavCqR8iSjKl4iiS70zgWTn3vRVsWTUWReGlVKFSxu9clxuN30ppdyjtyUqpVSQ00avlFJBThu9UkoFOW30SikV5LTRK6VUkNNGr5RSQU4bvVJKBTlt9EopFeT87lGCIpIG/FmAVcQCex0qx03Bsh+g++KvgmVfgmU/oGD7UsMYE5fbDL9r9AUlIonne25iIAmW/QDdF38VLPsSLPsBvtsXPXWjlFJBThu9UkoFuWBs9GPdLsAhwbIfoPvir4JlX4JlP8BH+xJ05+iVUkqdLRiP6JVSSnnQRq+UUkEuIBu9iHQXkfUikiwiT+YyP1JEptjzF4tIzcKv0jte7MttIpImIivs111u1JkXERknIntE5I/zzBcR+Z+9nytFpFVh1+gtL/blchE55PGZPFvYNXpDRKqJyDwRWSMiq0Xk/3JZJiA+Fy/3JVA+lygRWSIiSfa+jMxlGWd7mDEmoF5AKLAJqA1EAElAo3OWuR8YY389CJjidt0F2JfbgLfdrtWLfbkMaAX8cZ75PYFvAQHaA4vdrrkA+3I58LXbdXqxH5WAVvbXJYANufx8BcTn4uW+BMrnIkBx++twYDHQ/pxlHO1hgXhE3xZINsZsNsacBCYDvc9Zpjfwif31NOAqEZFCrNFb3uxLQDDGzAf2X2CR3sCnxrIIKC0ifvkgWS/2JSAYY3YaY363vz4CrAWqnLNYQHwuXu5LQLD/Wx+1vw23X+eOinG0hwVio68CbPf4PoW/fuCnlzHGZAKHgHKFUt3F8WZfAG6w/6yeJiLVCqc0x3m7r4Gig/2n97ci0tjtYvJi/+nfEuvo0VPAfS4X2BcIkM9FREJFZAWwB5hrjDnv5+JEDwvERl/UfAXUNMY0A+Zy5re8cs/vWLkizYG3gBku13NBIlIc+Bz4uzHmsNv1FEQe+xIwn4sxJssY0wKoCrQVkSa+3F4gNvpUwPOotqo9LddlRCQMKAXsK5TqLk6e+2KM2WeMybC//QBoXUi1Oc2bzy0gGGMO5/zpbYyZBYSLSKzLZeVKRMKxGuNEY8z0XBYJmM8lr30JpM8lhzHmIDAP6H7OLEd7WCA2+qVAXRGpJSIRWBcqZp6zzEzgVvvr/sCPxr6q4Wfy3Jdzzpf2wjo3GYhmAkPtUR7tgUPGmJ1uF5UfIlIx53ypiLTF+v/I7w4k7Bo/BNYaY944z2IB8bl4sy8B9LnEiUhp++to4Gpg3TmLOdrDwvL7RrcYYzJF5EFgDtaolXHGmNUiMgpINMbMxPqBGC8iyVgX1Qa5V/H5ebkvD4tILyATa19uc63gCxCRSVijHmJFJAUYjnWRCWPMGGAW1giPZOA4cLs7lebNi33pD9wnIpnACWCQnx5IdAJuAVbZ54MBngaqQ8B9Lt7sS6B8LpWAT0QkFOuXUYIx5mtf9jCNQFBKqSAXiKdulFJKXQRt9EopFeS00SulVJDTRq+UUkFOG71SSgU5bfRKKRXktNErpVSQ+38esiVCpYCb/gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(Accuracy_List)\n",
        "print(Precision_List)\n",
        "print(Recall_List)\n",
        "print(F1_List)\n",
        "\n",
        "Acc_av = 0\n",
        "Pre_av = 0\n",
        "Rec_av = 0\n",
        "F1L_av = 0\n",
        "for i in range(0,len(sample_sizes)):\n",
        "\n",
        "  Acc_av = Acc_av + Accuracy_List[i]\n",
        "  Pre_av = Pre_av + Precision_List[i]\n",
        "  Rec_av = Rec_av + Recall_List[i]\n",
        "  F1L_av = F1L_av + F1_List[i]\n",
        "Average = []\n",
        "\n",
        "Average.append(Acc_av/len(sample_sizes))\n",
        "Average.append(Pre_av/len(sample_sizes))\n",
        "Average.append(Rec_av/len(sample_sizes))\n",
        "Average.append(F1L_av/len(sample_sizes))\n",
        "print(Average)\n",
        "print(Bayes_Results)\n",
        "names = ['Average,Bayes','Results']\n",
        "pos = [0,1,2,3]\n",
        "plt.plot(pos,Average,Bayes_Results,label = names[0])\n",
        "plt.title('Figure 1')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data in figure one shows the two results, naive bayes as the yellow and the averages of the word list classifier in the blue. This then can be inturpretted to understand what it means at each point in comparison to the other. \n",
        "\n",
        "The data shown depicts on the base case of the naive bayes, it is higher in every catagory than the average of wordlist for the sample size chosen."
      ],
      "metadata": {
        "id": "Dpvt81ePY6vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "names = ['Accuracy','Precision','Recall','F1']\n",
        "\n",
        "grid=[sample_sizes]\n",
        "graphs=[\n",
        "        Accuracy_List,Precision_List,Recall_List,F1_List\n",
        "        ]\n",
        "\n",
        "for i in graphs:\n",
        "  Biggest = 0\n",
        "  num = 1\n",
        "  for j in i:\n",
        "    if j > Biggest:\n",
        "      Biggest = j\n",
        "      num = num + 1\n",
        "  print(num)\n",
        "  print(Biggest)\n",
        "\n",
        "for o,graph in enumerate(graphs):\n",
        "    plt.plot(sample_sizes,graph,label = str(names[o]))\n",
        "\n",
        "plt.legend(loc=3,bbox_to_anchor=(1,0))\n",
        "plt.xlabel('Sample Size')\n",
        "plt.title('Figure 2')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Hkv8dpNQr3IR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "131908d4-7e90-4224-9a99-33b280b00503"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "0.6416666666666667\n",
            "5\n",
            "0.5986078886310905\n",
            "8\n",
            "0.9566666666666667\n",
            "10\n",
            "0.7240506329113924\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) a) \n",
        "\n",
        "For the experiment, I have changed the values of the sample size by incremented values, this in turn increased the wordlist and the amount of word checks that are done. This means that for each review, the information inside is more valuable and words that had no impact now do. This increases all values to a certain point, however then fat gets in the way. words that shouldn't have much or any influence now do impact it and if a review repeated one word several times that had little influence on the actual meaning of the review, it could cause it to be classified differently.\n",
        " \n",
        "I decided to just run the accuracy tester the same number of values in the sample size, this means I can increase and change the sample size variation and that can be represented in the graph and the data I create.\n",
        " \n",
        "As seen in Figure 2, there is a general increase in all 4 areas, this is too a point however, and some strange anomalies can be seen in the data. For example, there is a spike in the value of recall, Accuracy and precision. However this is smoothed in the value of F1. There is a large dip in the data across all categories at point 20 to point 60, except the recall. This means that the data in this section has a lower precision, showing that it might find in this set more positives, though more of them are wrongly detected. The recall on the other hand is finding more of the correct positives rather though it is potentially identifying more negatives as positive. This shows that in the data set provided, and between teh word lists lengths of 20-60, more of the positive words appear in the reviews generally compared to the negative words. This represents potentially that there are less words to express that a review is good compared to negative words.\n",
        " \n",
        "In my opinion one of the best pieces of information can be seen in the value of F1 in Figure 2. This is because it shows, to an extent, what I predicted the data to appear as. A general increase in the abilities of my classifier as the word list increased in size. This general increase is interrupted by the dip I identified above, which in general seems to show that more of the classifications were wrong and more than usual were being assigned positive values. This is good information, as it can mean several things; there are more ways to represent a bad review in the words used, or it could mean that more common words that appear in all reviews are in this section of the positive word list frequency, meaning more are falsely identified as positive.\n"
      ],
      "metadata": {
        "id": "bwmOXA36zNO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) b)\n",
        "\n",
        "As a result of the data I have accumulated, I would recommend the naive bayes classifier. This is because no matter the data set size i put in, with the current configuration of it the values of my classifier are even at their highest worse than that of the naive bayes in every field. In the graph labelled figure 1, the data shows bayes results in yellow, and my average results for all the variations in blue. This is offset by a similar amount, meaning roughly they perform the same, however totally it is worse on every point. Even at its best result, as seen above Figure 2, the results are still less than that of the bayes version.\n",
        " \n",
        "Therefore, I would recommend the bayes classifier. If the one I created had different bands of classification, adding different score values it might do better, however for the version I have made it is worse in every aspect. \n",
        " \n",
        "As well as this lower quality of a result, there is also a further problem. The runtime of the classifier is already very large and as the data set increases it increases as well. This may not seem like a large issue, however if you wanted to train and execute the data upon a much larger data set than the one we have been provided the runtime could become many times worse than it already is, for a worse result. Whereas the naive bayes algorithm takes into account the best words and still can execute in a decent time.\n",
        "\n",
        "Changes have been made to the code in order to reduce the run time, and more could be made to increase its efficently. However because of the way that it is meant to work, with iteration over each word in each review in an entire data set, the performance becomes drastically worse as the data set increases. This doesnt mean the naive bayes doesnt, however at least with my configuration it worse quicker than the naive bayes. This could be another interesting data set, to experiment upon the running time of a fixed sized data set and increased word list length or increased data sets compared with accuracy.\n",
        "\n",
        "Seen just above figure two is a set of 4 data samples, this is the highest that each catagory could achieve and the position in the data sample that it takes it from. Even using this information, of the best my classifier could do dependant on wordlist size, it still could not pass the naive bayes classifier in a single catagory demonstrating well that the naive bayes is better. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3mTQxPLCIwl2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "34rdlS_iPov6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a561add8-f338-4922-ac51-2c9e31286224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Submission length is 2314\n"
          ]
        }
      ],
      "source": [
        "##This code will word count all of the markdown cells in the notebook saved at filepath\n",
        "##Running it before providing any answers shows that the questions have a word count of 437\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import io\n",
        "from nbformat import current\n",
        "\n",
        "filepath=\"/content/drive/My Drive/NLENotebooks/assessment/NLassignment2022_232560.ipynb\"\n",
        "#filepath=\"NLassignment2022.ipynb\"\n",
        "question_count=437\n",
        "\n",
        "with io.open(filepath, 'r', encoding='utf-8') as f:\n",
        "    nb = current.read(f, 'json')\n",
        "\n",
        "word_count = 0\n",
        "for cell in nb.worksheets[0].cells:\n",
        "    if cell.cell_type == \"markdown\":\n",
        "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
        "print(\"Submission length is {}\".format(word_count-question_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "PtqCcG6wPsmf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w3vKVlY2Wppk"
      },
      "execution_count": 48,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}